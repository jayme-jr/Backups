title: Estatística Aplicada às Ciências Sociais
title: "Estatística Aplicada às Ciências Sociais"
Estatística Aplicada as Ciencias Sociais
# Estatística Aplicada as Ciencias Sociais
========================================================
author: Maria Helena Oliveira
install.packages("devtools")
install.packages("roxygen2")
require(labestdata)
install_git(url = "https://gitlab.c3sl.ufpr.br/pet-estatistica/labestData.git",
branch = "master")
install_git(url = "https://gitlab.c3sl.ufpr.br/pet-estatistica/labestData.git",
branch = "master")
install.packages("tm")
library('tm')
file = '/home/petest/Downloads/[Bayo_Lawal,_H._Bayo_Lawal]_Categorical_data_analy(BookZZ.org).pdf'
library('tm')
Rpdf <- readPDF(control = list(text = "-layout"))
corpus <- VCorpus(URISource(file),
readerControl = list(reader = Rpdf))
corpus.array <- content(content(corpus)[[1]])
corpus.array
exeFile <- file
for(i in 1:length(pdfFracList)){
fileNumber <- str_sub(pdfFracList[i], start = 1, end = -5)
pdfSource <- paste0(reportDir,"/", fileNumber, ".pdf")
txtDestination <- paste0(reportDir,"/", fileNumber, ".txt")
print(paste0("File number ", i, ", Processing file ", pdfSource))
system(paste(exeFile, "-table" , pdfSource, txtDestination, sep = " "), wait = TRUE)
}
install.packages("pdftools")
require(pdftools)
txt <- pdf_text(file)
require(pdftools)
txt <- pdf_text(file)
txt <- pdf_text("http://arxiv.org/pdf/1406.4806.pdf")
require(pdftools)
install.packages("pdftools")
require(pdftools)
txt <- pdf_text(file)
txt
attributes(txt)
names(txt)
str(txt)
table(txt)
txt <- pdf_text("http://arxiv.org/pdf/1406.4806.pdf")
cat(txt[18])
cat(txt[19])
txt[18]
whhsthhatejhnetaj
install.packages("bookdown")
system("apt-cache search selenium")
browseURL("http://selenium-release.storage.googleapis.com/index.html")
url <- paste0("http://selenium-release.storage.googleapis.com/",
"3.0/selenium-server-standalone-3.0.1.jar")
download.file(url = url,
destfile = paste0("~/Downloads/", basename(url)))
dir(path = "~/Downloads", pattern = "*.jar")
cmd <- sprintf("java -jar %s", basename(url))
install.packages("RSelenium")
library(RSelenium)
help(rsDriver, h = "html")
rD <- rsDriver(browser = "firefox", phantomver = NULL)
remDr <- rD[["client"]]
rD <- rsDriver(browser = "firefox", phantomver = NULL)
library(RSelenium)
rD <- rsDriver(browser = "firefox", phantomver = NULL)
rD <- rsDriver(browser = "firefox")
rsDriver()
system("apt-cache search selenium")
browseURL("http://selenium-release.storage.googleapis.com/index.html")
url <- paste0("http://selenium-release.storage.googleapis.com/",
"3.0/selenium-server-standalone-3.0.1.jar")
download.file(url = url,
destfile = paste0("~/Downloads/", basename(url)))
dir(path = "~/Downloads", pattern = "*.jar")
cmd <- sprintf("java -jar %s", basename(url))
cmd
rD <- rsDriver(browser = "firefox")
runif(min = 1, max = 100, n = 10)
s <- c(1,2,3,4)
runif(s)
runif(min = 1, max = 3, n = 10)
runif(min = 1, max = 4, n = 4)
runif(20)
dunif(20)
punif(20)
dunif(min = 1, max = 4, n = 4)
dunif(min = 1, max = 4, n = 4)
runif(min = 1, max = 4, n = 4)
RNGkind[1:4]
runif(min = 1, max = 4, n = 4)
candidatos <- c("augusto", "Nilton", "Pedro", "Willian")
sample(candidatos, 2)
sample(candidatos, 2)
sample(candidatos, 2)
sample(candidatos, 2)
setwd("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Sentimento_teste.RData")
library(tm)
cps_maio <- Corpus(VectorSource(tweets_maio),
readerControl = list(language = "pt"))
head(cps_maio)
cps_maio
cps_maio <- tm_map(cps_maio, FUN = content_transformer(tolower))
cps_maio <- tm_map(cps_maio, FUN = removePunctuation)
cps_maio <- tm_map(cps_maio, FUN = removeNumbers)
cps_maio <- tm_map(cps_maio, FUN = stripWhitespace)
dtm_maio <- DocumentTermMatrix(cps_maio)
inter_maio <- intersect(x = Terms(dtm_maio),
y = sent$term)
length(inter_maio)
lex_maio <- merge(x = data.frame(term = inter_maio,
stringsAsFactors = FALSE),
y = sent,
sort = FALSE)
str(lex_maio)
save.image("Sentimento_teste.RData")
m_maio <- as.matrix(dtm_maio)
cps_maio
library(jsonlite)
i <- 1
tweets_maio_1 <- list()
abril <- head(seq(as.Date("2017-04-17"),
as.Date("2017-05-01"),
by = "1 days"), n = -1)
maio <- head(seq(as.Date("2017-05-01"),
as.Date("2017-06-01"),
by = "1 days"), n = -1)
junho <- head(seq(as.Date("2017-06-01"),
as.Date("2017-07-01"),
by = "1 days"), n = -1)
julho <- head(seq(as.Date("2017-07-01"),
as.Date("2017-08-01"),
by = "1 days"), n = -1)
agosto <- head(seq(as.Date("2017-08-01"),
as.Date("2017-09-01"),
by = "1 days"), n = -1)
host <- "http://api.miti.com.br:7863/api/v1"
token <- "edc01a6712ade3b25de804fbdade848d311ef6ec"
url <- paste0(host, "/profile/info?token=", token)
doc <- fromJSON(txt = url)
str(doc)
idperfil <- doc$data$perfis$id_perfil
url <- paste0(host, "/profile/", idperfil, "/info?token=", token)
doc <- fromJSON(txt = url)
str(doc)
doc$data$palavras
idpalavra <- "380710"
while(i <= 15){
dia <- maio[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_maio <- fromJSON(txt = url)
tweets_maio_1 <- append(tweets_maio_1,
sapply(per_maio_1$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
while(i <= 15){
dia <- maio[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_maio <- fromJSON(txt = url)
tweets_maio_1 <- append(tweets_maio_1,
sapply(per_maio$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_maio_1)
save.image("Maio_1.RData")
save(tweets_maio_1, file = "Maio.RData")
i
save(tweets_maio_1, file = "Maio_1.RData")
save(tweets_maio_1, file = "Maio_1.RData")
tweets_maio_2 <- list()
while(i <= length(maio)){
dia <- maio[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_maio <- fromJSON(txt = url)
tweets_maio_2 <- append(tweets_maio_2,
sapply(per_maio$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_maio_2)
save(tweets_maio_1, file = "Maio_2.RData")
save(tweets_maio_2, file = "Maio_2.RData")
junho <- head(seq(as.Date("2017-06-01"),
as.Date("2017-07-01"),
by = "1 days"), n = -1)
julho <- head(seq(as.Date("2017-07-01"),
as.Date("2017-08-01"),
by = "1 days"), n = -1)
agosto <- head(seq(as.Date("2017-08-01"),
as.Date("2017-09-01"),
by = "1 days"), n = -1)
i <- 1
tweets_junho_1 <- list()
while(i <= 15){
dia <- junho[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_junho <- fromJSON(txt = url)
tweets_junho_1 <- append(tweets_junho_1,
sapply(per_junho$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_junho_1)
save(tweets_junho_1, file = "Junho_1.RData")
i
tweets_junho_2 <- list()
while(i <= length(junho)){
dia <- junho[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_junho <- fromJSON(txt = url)
tweets_junho_2 <- append(tweets_junho_2,
sapply(per_junho$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_junho_2)
save(tweets_junho_2, file = "Junho_2.RData")
i <- 1
tweets_julho_1 <- list()
while(i <= 15){
dia <- julho[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_julho <- fromJSON(txt = url)
tweets_julho_1 <- append(tweets_julho_1,
sapply(per_julho$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_julho_1)
save(tweets_julho_1, file = "Julho_1.RData")
tweets_julho_2 <- list()
while(i <= length(julho)){
dia <- julho[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_julho <- fromJSON(txt = url)
tweets_julho_2 <- append(tweets_julho_2,
sapply(per_julho$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_julho_2)
save(tweets_julho_2, file = "Julho_2.RData")
i <- 1
tweets_agosto_1 <- list()
while(i <= 15){
dia <- agosto[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_agosto <- fromJSON(txt = url)
tweets_agosto_1 <- append(tweets_agosto_1,
sapply(per_agosto$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_agosto_1)
save(tweets_agosto_1, file = "Agosto_1.RData")
tweets_agosto_2 <- list()
while(i <= length(agosto)){
dia <- agosto[i]
url <- paste0("http://api.miti.com.br:7863",
"/api/v1/profile/29312/search/news?",
"midias=online",
"&id_palavra=", idpalavra,
"&date=", dia,
"&page=1",
"&token=", token)
per_agosto <- fromJSON(txt = url)
tweets_agosto_2 <- append(tweets_agosto_2,
sapply(per_agosto$data, FUN = "[[",
"str_conteudo_html"))
i <- i + 1
}
head(tweets_agosto_2)
save(tweets_agosto_2, file = "Agosto_2.RData")
setwd("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Abril.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Agosto_1.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Agosto_2.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Julho_1.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Julho_2.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Junho_1.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Junho_2.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Maio_1.RData")
load("~/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/Maio_2.RData")
cps_maio_1 <- Corpus(VectorSource(tweets_maio_1),
readerControl = list(language = "pt"))
head(cps_maio_1)
cps_maio_1
cps_maio_1 <- tm_map(cps_maio_1, FUN = content_transformer(tolower))
cps_maio_1 <- tm_map(cps_maio_1, FUN = removePunctuation)
cps_maio_1 <- tm_map(cps_maio_1, FUN = removeNumbers)
cps_maio_1 <- tm_map(cps_maio_1, FUN = stripWhitespace)
dtm_maio_1 <- DocumentTermMatrix(cps_maio_1)
dtm_maio_1
inter_maio_1 <- intersect(x = Terms(dtm_maio_1),
y = sent$term)
sent <- read.table("/home/petest/Área de Trabalho/JR/Jayme/Pesquisa/Ambiente_de_teste/lexico_v3.0.txt",
header = FALSE,
sep = ",",
quote = "",
stringsAsFactors = FALSE)
names(sent) <- c("term", "class", "pol", "ann")
head(sent)
inter_maio_1 <- intersect(x = Terms(dtm_maio_1),
y = sent$term)
length(inter_maio_1)
lex_maio_1 <- merge(x = data.frame(term = inter_maio_1,
stringsAsFactors = FALSE),
y = sent,
sort = FALSE)
str(lex_maio_1)
m_maio_1 <- as.matrix(dtm_maio_1)
m_maio_1 <- m_maio_1[, lex_maio_1$term]
ncol(m_maio_1) == nrow(lex_maio_1)
all(colnames(m_maio_1) == lex_maio_1$term)
soma_maio_1 <- m_maio_1 %*% cbind(lex_maio_1$pol)
total_maio_1 <- sum(soma_maio_1[,1])
total_maio_1
save(soma_maio_1, file = "sentimento_Maio_1.RData")
save(total_maio_1, file = "resultado_Maio_1.RData")
